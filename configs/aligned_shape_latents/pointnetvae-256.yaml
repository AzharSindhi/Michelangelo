model:
  target: michelangelo.models.tsal.asl_pl_module.AlignedShapeAsLatentPLModule
  params:
    ckpt_path: "checkpoints/aligned_shape_latents/pointnetvae-256.ckpt"
    shape_module_cfg:
      target: michelangelo.models.pointnet_vae.pointnet2_vae.PointNet2CloudCondition
      params:
          model_name: "pointnet"
          in_fea_dim: 3
          partial_in_fea_dim: 0
          out_dim: 3
          include_t: false
          t_dim: 128
          "model.use_xyz": true
          attach_position_to_input_feature: true
          include_abs_coordinate: true
          include_center_coordinate: true
          record_neighbor_stats: false
          bn_first: false
          bias: true
          res_connect: true
          map_type: "cross_attention"
          condition_loss: true
          image_fusion_strategy: "none"
          include_class_condition: false
          image_backbone: "none"
          use_cross_conditioning: false
          num_class: 256
          class_condition_dim: 128
          gamma: 0.5
          scale_factor: 1
          bn: true
          include_local_feature: true
          include_global_feature: true
          global_feature_remove_last_activation: false
          pnet_global_feature_architecture:
            - [3, 128, 256]
            - [512, 1024]
          attention_setting:
            use_attention_module: true
            attention_bn: true
            transform_grouped_feat_out: true
            last_activation: true
            add_attention_to_FeatureMapper_module: true
          architecture:
            npoint: [2048, 512, 128, 32]
            radius: [0.1, 0.2, 0.4, 0.8]
            neighbor_definition: "radius"
            nsample: [32, 32, 32, 32]
            feature_dim: [128, 128, 256, 256, 512]
            mlp_depth: 3
            decoder_feature_dim: [128, 128, 256, 256, 512]
            include_grouper: false
            decoder_mlp_depth: 2
            use_knn_FP: true
            K: 8
          condition_net_architecture:
            npoint: [2048, 512, 128, 32]
            radius: [0.1, 0.2, 0.4, 0.8]
            neighbor_definition: "radius"
            nsample: [32, 32, 32, 32]
            feature_dim: [128, 128, 256, 256, 512]
            mlp_depth: 3
            decoder_feature_dim: [128, 128, 256, 256, 512]
            include_grouper: false
            decoder_mlp_depth: 2
            use_knn_FP: true
            K: 8
          feature_mapper_architecture:
            neighbor_definition: "radius"
            encoder_feature_map_dim: [32, 32, 64, 64]
            encoder_mlp_depth: 2
            encoder_radius: [0.1, 0.2, 0.4, 0.8]
            encoder_nsample: [32, 32, 32, 32]
            decoder_feature_map_dim: [32, 32, 64, 64, 128]
            decoder_mlp_depth: 2
            decoder_radius: [0.1, 0.2, 0.4, 0.8, 1.6]
            decoder_nsample: [32, 32, 32, 32, 32]
          clip_processor:
            model_name: "clip_processor"
            clip_model_name: "clip_vit_b_32"
            clip_model_path: ""
            clip_dim: 512
            class_names: ["bathtub", "bed", "chair", "desk", "dresser", "monitor", "night_stand", "sofa", "table", "toilet"]

    aligned_module_cfg:
      target: michelangelo.models.tsal.dino_asl_module.DinoAlignedShapeAsLatentModule
      params:
        clip_model_version: "facebook/dinov2-large"
        use_contrastive: true
    
    dropout: 0.1
    num_decoder_layers_cross_attn: 2
    numpoints: 4096

    loss_cfg:
      target: michelangelo.models.tsal.loss.ContrastKLNearFar
      params:
        contrast_weight: 0.1
        chamfer_weight_pc: 0.3
        chamfer_weight_partial: 0.1
        mse_weight: 0.0
        kl_weight: 0.001
    
    optimizer_cfg:
      optimizer:
        target: torch.optim.AdamW
        params:
          betas: [0.9, 0.99]
          # eps: 1.e-6
          lr: 1.e-4 #1.e-3
          weight_decay: 1.e-2
      scheduler:
        target: torch.optim.lr_scheduler.ReduceLROnPlateau
        params:
          mode: "min"
          factor: 0.1
          patience: 10
          cooldown: 0
          min_lr: 1e-6

data:
  data_dir: "~/Documents/datasets/ShapeNetViPC-Dataset"
  num_workers: 4
  view_align: true
  category: "plane"
  mini: true
  image_size: 224


# training params
batch_size: 16
strategy: ddp #ddp_find_unused_parameters_false
devices: -1
max_epochs: 2000
use_ckpt: false
use_swa: false
use_lr_finder: false
max_lr: 1.e-3 # if lr_finder is true, this will be used as max_lr
log_every_n_steps: 5
accumulate_grad_batches: 4
gradient_clip_val: 0.5
check_val_every_n_epoch: 50  # Run validation once per 5 epochs
fast_dev_run: false
limit_train_batches: null
limit_val_batches: null
overfit_batches: 1
resume_from_ckpt: null
precision: "16"